{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import slam_utils as su\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max dist: 94.0\n",
      "Min dist: 4.0\n",
      "Number of matches: 79\n"
     ]
    }
   ],
   "source": [
    "img_1 = cv.imread(\"./1.png\")\n",
    "img_2 = cv.imread(\"./2.png\")\n",
    "keypoints_1, keypoints_2, matches = su.find_feature_matches(img_1, img_2)\n",
    "print(f\"Number of matches: {len(matches)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fundamental_matrix is \n",
      "[[ 4.54443750e-06  1.33385558e-04 -1.79849925e-02]\n",
      " [-1.27565701e-04  2.26679480e-05 -1.41667843e-02]\n",
      " [ 1.81499464e-02  4.14605587e-03  1.00000000e+00]]\n",
      "essential_matrix is \n",
      "[[-0.00216635  0.10710349  0.09822344]\n",
      " [-0.05307032  0.03077166 -0.69811902]\n",
      " [-0.05867768  0.69562353  0.02018946]]\n",
      "homography_matrix is \n",
      "[[ 9.48831932e-01 -1.51560188e-01  3.37818532e+01]\n",
      " [ 4.01832734e-02  9.68309989e-01  7.00140362e+00]\n",
      " [-3.02186330e-05  5.07624222e-05  1.00000000e+00]]\n",
      "R is [[ 0.99530005 -0.05374526  0.08055587]\n",
      " [ 0.05063772  0.99791026  0.04013642]\n",
      " [-0.08254468 -0.03586862  0.99594167]]\n",
      "t is [[-0.97864836]\n",
      " [-0.13316516]\n",
      " [ 0.15657086]]\n"
     ]
    }
   ],
   "source": [
    "R, t = su.pose_estimation_2d2d(keypoints_1, keypoints_2, matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t^R= \n",
      "[[ 0.          0.00841494 -0.01072724]\n",
      " [ 0.00792839 -0.          0.03927944]\n",
      " [-0.01099208  0.03510276  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Check E = t^R*scale\n",
    "t_x = np.cross(np.eye(3), t.transpose())\n",
    "print(f\"t^R= \\n{t_x*R}\")  # I guess this is scale simular to E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check epipolar constraints (commented out)\n",
    "# Convert pixel coordinates to camera coordinates\n",
    "K = np.array([[520.9, 0, 325.1], [0, 521.0, 249.7], [0, 0, 1]])\n",
    "# These have to be 2xN numpy arrays\n",
    "pts_1 = np.empty((2, 0))\n",
    "pts_2 = np.empty((2,0))\n",
    "for m in matches:\n",
    "    pt1 = su.pixel2cam(keypoints_1[m.queryIdx].pt, K)\n",
    "    # y1 = np.array([[pt1[0]], [pt1[1]], [1]])\n",
    "    pt2 = su.pixel2cam(keypoints_2[m.trainIdx].pt, K)\n",
    "    # y2 = np.array([[pt2[0]], [pt2[1]], [1]])\n",
    "    # d = np.dot(np.dot(y2.transpose(), t_x), np.dot(R, y1))\n",
    "    # print(f\"epipolar constraint: {d}\")\n",
    "    pts_1 = np.hstack([pts_1, np.array(pt1).reshape(-1, 1)])\n",
    "    pts_2 = np.hstack([pts_2, np.array(pt2).reshape(-1, 1)])\n",
    "points3D = su.triangulation(R, t, pts_1, pts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_color(depth):\n",
    "    up_th = 11.7\n",
    "    low_th = 6.4\n",
    "    th_range = up_th - low_th\n",
    "    if depth > up_th:\n",
    "        depth = up_th\n",
    "    if depth < low_th:\n",
    "        depth = low_th\n",
    "    scaled_range = depth-low_th\n",
    "    color = tuple(int(x) for x in (255 * scaled_range/th_range, 0, 255 * (1 - scaled_range/th_range)))\n",
    "    return color\n",
    "\n",
    "\n",
    "# plot the points with color depth\n",
    "img1_plot = img_1.copy()\n",
    "img2_plot = img_2.copy()\n",
    "for i in range(len(matches)):\n",
    "    depth1 = points3D[i][2]\n",
    "    pix1 = tuple(int(x) for x in keypoints_1[matches[i].queryIdx].pt)\n",
    "    pt1_cam = su.pixel2cam(keypoints_1[matches[i].queryIdx].pt, K)\n",
    "    cv.circle(img1_plot, pix1, 2, get_color(depth1), 2)\n",
    "    pt2_trans = R.dot(points3D[i]) + t\n",
    "    depth2 = pt2_trans[2]\n",
    "    pix2 = tuple(int(x) for x in keypoints_2[matches[i].trainIdx].pt)\n",
    "    cv.circle(img2_plot, pix2, 2, get_color(depth2), 2)\n",
    "cv.imshow(\"img_1\", img1_plot)\n",
    "cv.imshow(\"img_2\", img2_plot)\n",
    "cv.waitKey()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
